{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Document Clustering using K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Number of Clusters =  3\n",
      "\n",
      "\tPurity: \t 0.8943820224719101\n",
      "\tRecall: \t 0.22690365354775005\n",
      "\tPrecision: \t 0.11377205343965438\n",
      "\tF-score: \t 0.151456872758047\n",
      "\n",
      "For Number of Clusters =  5\n",
      "\n",
      "\tPurity: \t 0.8557303370786516\n",
      "\tRecall: \t 0.14892937200121675\n",
      "\tPrecision: \t 0.206542005262187\n",
      "\tF-score: \t 0.16989975074055141\n",
      "\n",
      "For Number of Clusters =  7\n",
      "\n",
      "\tPurity: \t 0.7051685393258427\n",
      "\tRecall: \t 0.1304491707522349\n",
      "\tPrecision: \t 0.1469546456591608\n",
      "\tF-score: \t 0.1372836239997945\n",
      "\n",
      "For Number of Clusters =  9\n",
      "\n",
      "\tPurity: \t 0.621123595505618\n",
      "\tRecall: \t 0.09267494898776624\n",
      "\tPrecision: \t 0.2255795961904945\n",
      "\tF-score: \t 0.12925488103162971\n"
     ]
    }
   ],
   "source": [
    "import collections, nltk, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tokenization and Stemming of Words\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = [PorterStemmer().stem(item) for item in tokens]\n",
    "    return stems\n",
    "\n",
    "# Compute Confusion Matrix and Purity\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    #purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis = 1)) / np.sum(contingency_matrix)\n",
    "    \n",
    "# Import Dataset\n",
    "documents = pd.read_csv(\"bbc-text.csv\")\n",
    "\n",
    "# Label Encoding\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "documents['category'] = labelEncoder.fit_transform(documents['category'])\n",
    "\n",
    "df = pd.DataFrame(list(zip(documents['text'], documents['category']))\n",
    "                  ,columns = ['text', 'label'])\n",
    "\n",
    "# Creating TF/IDF Vectors from Text\n",
    "tfidfvectorizer = TfidfVectorizer(tokenizer = tokenize, stop_words = 'english')\n",
    "x = tfidfvectorizer.fit_transform(df.text.values)\n",
    "\n",
    "# Clustering with Different K Values\n",
    "for no_of_clusters in (3,5,7,9):\n",
    "    # Build the K Means Model\n",
    "    model = KMeans(n_clusters = no_of_clusters)\n",
    "\n",
    "    # Train the Model \n",
    "    model.fit_transform(x)\n",
    "    clusters = collections.defaultdict(list)\n",
    "    for doc_id, label in enumerate(model.labels_):\n",
    "        clusters[label].append(doc_id)\n",
    "    purity = purity_score(y_true = df.label, y_pred = model.labels_)\n",
    "\n",
    "    # Output: Performance Measures\n",
    "    print(\"\\nFor Number of Clusters = \", no_of_clusters)\n",
    "    print(\"\\n\\tPurity: \\t\",purity)\n",
    "    print(\"\\tRecall: \\t\",metrics.recall_score(y_pred=model.labels_,\n",
    "                                              y_true=df.label,average='macro'))\n",
    "    print(\"\\tPrecision: \\t\",metrics.precision_score(y_pred=model.labels_,\n",
    "                                                    y_true=df.label,average='macro'))\n",
    "    print(\"\\tF-score: \\t\",metrics.f1_score(y_pred=model.labels_,\n",
    "                                           y_true=df.label,average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
